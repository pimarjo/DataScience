, replace = F)
#On crée les bases et la liste
lbase.cout.oh <- list(full = base.cout.oh
, train = base.cout.oh[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.cout.oh$train,10)
head(lbase.cout.oh$valid,10)
head(lbase.cout.oh$test,10)
# #On crée une liste des bases au format xgbMatrix
lbase.cout.xgb <- list(train = xgb.DMatrix(data = as.matrix(lbase.cout.oh$train[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$train[,'MeanClaimAmount'])
,test = xgb.DMatrix(data = as.matrix(lbase.cout.oh$test[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$test[,'MeanClaimAmount'])
,valid = xgb.DMatrix(data = as.matrix(lbase.cout.oh$valid[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$valid[,'MeanClaimAmount'])
)
################################################
###################_____    Modélisation
################################################
#######################################
######################_____ Package GBM
#######################################
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ VehGas + VehBrand + VehAge + VehPower + DrivAge + Area +  BonusMalus + Region + Density
,distribution = "gaussian"
,n.trees = 1000
,shrinkage = 0.01
,interaction.depth = 25
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- predict(m.gbm.defaut, lbase.cout$train, n.trees = 1000)
(pred - lbase.cout$train$MeanClaimAmount)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ VehGas + VehBrand + VehAge + VehPower + DrivAge + Area +  BonusMalus + Region + Density
,distribution = "gaussian"
,n.trees = 1000
,shrinkage = 0.01
,interaction.depth = 60
)
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ VehGas + VehBrand + VehAge + VehPower + DrivAge + Area +  BonusMalus + Region + Density
,distribution = "gaussian"
,n.trees = 1000
,shrinkage = 0.01
,interaction.depth = 10
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- predict(m.gbm.defaut, lbase.cout$train, n.trees = 1000)
(pred - lbase.cout$train$MeanClaimAmount)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ VehGas + VehBrand + VehAge + VehPower + DrivAge + Area +  BonusMalus + Region + Density
,distribution = "gaussian"
,n.trees = 10000
,shrinkage = 0.01
,interaction.depth = 10
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- predict(m.gbm.defaut, lbase.cout$train, n.trees = 1000)
(pred - lbase.cout$train$MeanClaimAmount)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ + VehBrand + VehAge + VehPower + DrivAge + Region + Density
,distribution = "gaussian"
,n.trees = 10000
,shrinkage = 0.01
,interaction.depth = 10
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- predict(m.gbm.defaut, lbase.cout$train, n.trees = 1000)
(pred - lbase.cout$train$MeanClaimAmount)^2 %>% mean() %>% sqrt()
bst_slow = xgb.train(data = lbase.cout.xgb$train
, max.depth = 7
, alpha = 0
, lambda = 1
, eta = 0.01
, nthread = 2
, nround = 10000
, watchlist = watchlist
, objective = "reg:linear"
, print_every_n = 500
,early_stopping_rounds = 50)
watchlist <- list(train = lbase.cout.xgb$train, valid = lbase.cout.xgb$valid)
bst_slow = xgb.train(data = lbase.cout.xgb$train
, max.depth = 7
, alpha = 0
, lambda = 1
, eta = 0.01
, nthread = 2
, nround = 10000
, watchlist = watchlist
, objective = "reg:linear"
, print_every_n = 500
,early_stopping_rounds = 50)
watchlist <- list(train = lbase.cout.xgb$train, valid = lbase.cout.xgb$valid, test = lbase.cout.xgb$test)
bst_slow = xgb.train(data = lbase.cout.xgb$train
, max.depth = 7
, alpha = 0
, lambda = 1
, eta = 0.01
, nthread = 2
, nround = 10000
, watchlist = watchlist
, objective = "reg:linear"
, print_every_n = 500
,early_stopping_rounds = 50)
bst_slow = xgb.train(data = lbase.cout.xgb$train
, max.depth = 10
, alpha = 0
, lambda = 1
, eta = 0.01
, nthread = 2
, nround = 10000
, watchlist = watchlist
, objective = "reg:linear"
, print_every_n = 500
,early_stopping_rounds = 50)
watchlist <- list(train = lbase.cout.xgb$train, valid = lbase.cout.xgb$valid)
bst_slow = xgb.train(data = lbase.cout.xgb$train
, max.depth = 10
, alpha = 0
, lambda = 1
, eta = 0.01
, nthread = 2
, nround = 10000
, watchlist = watchlist
, objective = "reg:linear"
, print_every_n = 500
,early_stopping_rounds = 50)
y_hat_valid = predict(bst_slow, lbase.cout.xgb$test)
test_mse = mean(((y_hat_valid - lbase.cout.oh$test[,'MeanClaimAmount'])^2))
test_rmse = sqrt(test_mse)
test_rmse
base.freq <- c(base,data.frame(ClaimNbAnnual = base$ClaimNb/base$Exposure))
#Les proportions que l'on veut pour nos différentes bases
proportion.train <- 0.5
porportion.valid <- 0.25
proportion.test <- 0.25
#Les indices pour la base de train
sample.train <- base.freq %>% nrow() %>% sample.int(n = .
, size = floor(proportion.train*.)
, replace = F)
base.freq %>% nrow()
base.freq <- c(base,data.frame(ClaimNbAnnual = base$ClaimNb/base$Exposure))
base.freq %>% nrow()
base.freq %>% head()
#On stocke toute les bases dans une liste de base, c'est plus simple à utiliser
#Les indices pour la base de train
sample.train <- base.freq$IDpol %>% nrow() %>% sample.int(n = .
, size = floor(proportion.train*.)
, replace = F)
base.freq$IDpol %>% nrow()
base.freq <- data.frame(base,data.frame(ClaimNbAnnual = base$ClaimNb/base$Exposure))
#Les proportions que l'on veut pour nos différentes bases
proportion.train <- 0.5
porportion.valid <- 0.25
proportion.test <- 0.25
#On stocke toute les bases dans une liste de base, c'est plus simple à utiliser
#Les indices pour la base de train
sample.train <- base.freq %>% nrow() %>% sample.int(n = .
, size = floor(proportion.train*.)
, replace = F)
#Une base temporaire qui les reste de la base initiale après la division pour la de train
base.temp <- base.freq[-sample.train,]
sample.test <- base.temp %>% nrow() %>% sample.int(n=.
, size = floor(porportion.valid/proportion.train*.)
, replace = F)
#On crée les bases et la liste
lbase.freq <- list(full = base.freq
, train = base.freq[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.freq$train,10)
head(lbase.freq$valid,10)
head(lbase.freq$test,10)
base.freq <- data.frame(base,data.frame(ClaimNbAnnual = base$ClaimNb/base$Exposure))
#Les proportions que l'on veut pour nos différentes bases
proportion.train <- 0.5
porportion.valid <- 0.25
proportion.test <- 0.25
#On stocke toute les bases dans une liste de base, c'est plus simple à utiliser
#Les indices pour la base de train
sample.train <- base.freq %>% nrow() %>% sample.int(n = .
, size = floor(proportion.train*.)
, replace = F)
#Une base temporaire qui les reste de la base initiale après la division pour la de train
base.temp <- base.freq[-sample.train,]
sample.test <- base.temp %>% nrow() %>% sample.int(n=.
, size = floor(porportion.valid/proportion.train*.)
, replace = F)
#On crée les bases et la liste
lbase.freq <- list(full = base.freq
, train = base.freq[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.freq$train,10)
head(lbase.freq$valid,10)
head(lbase.freq$test,10)
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNbAnnual ~  VehBrand + VehAge  + DrivAge + Area + Region
,distribution = "poisson"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
)
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNbAnnual ~  VehBrand + VehAge  + DrivAge + Area + Region
,distribution = "gaussian"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
head(pred,100)
lbase.freq$full %>% summary()
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
head(pred,100)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNbAnnual ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus
,distribution = "gaussian"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
pred %>% max()
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNbAnnual ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus
,distribution = "gaussian"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
head(pred,100)
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus +offset(log(Exposure))
,distribution = "gaussian"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
install.packages("h2o")
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus +offset(log(Exposure))
,distribution = "gaussian"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus +offset(log(Exposure))
,distribution = "poisson"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
pred
lbase.freq %>% summary()
lbase.freq$full %>% summary()
#On formate les données de la base de frequence
frequence$IDpol <- as.factor(frequence$IDpol)
#On formate la base de cout
severite$IDpol <- as.factor(severite$IDpol)
rm(list =ls())
#setwd("~/DataScience-master")
library(magrittr)
library(rpart)
library(rpart.plot)
#setwd("~/ISFA/3A/Data Science/ProjetDataScience/DataScience/data")
#Initialisation des donnees ----
# load("data/freMTPL2freq.rda")
# load("data/freMTPL2sev.rda")
data("freMTPL2freq")
data("freMTPL2sev")
# On récupère les deux datasets :
data(freMTPL2freq)
data(freMTPL2sev)
frequence <- freMTPL2freq
severite <- freMTPL2sev
rm(freMTPL2freq, freMTPL2sev)
#Mise en forme des donnéees ----
#Enlèvons Density?
#frequence <-frequence[, ! colnames(frequence) %in% "Density"]
#On formate les données de la base de frequence
frequence$IDpol <- as.factor(frequence$IDpol)
frequence$ClaimNb <- frequence$ClaimNb %>% unname() %>% as.numeric()
frequence$VehPower <- as.integer(frequence$VehPower)
frequence$Exposure <- as.double(frequence$Exposure)
frequence$Area <- as.factor(frequence$Area)
frequence$VehAge <- as.integer(frequence$VehAge)
frequence$DrivAge <- as.integer(frequence$DrivAge)
frequence$BonusMalus <- as.integer(frequence$BonusMalus)
frequence$VehBrand <- as.factor(frequence$VehBrand)
frequence$VehGas <- as.factor(frequence$VehGas)
frequence$Region <- as.factor(frequence$Region)
#On formate la base de cout
severite$IDpol <- as.factor(severite$IDpol)
severite$ClaimAmount <- as.numeric(severite$ClaimAmount)
#On prends que les exposures inférieures à 1 ?
frequence <- frequence[frequence$Exposure <= 1,]
#######################################################################################################
######################_________________________   Gradient boosting
#######################################################################################################
library(caret)
library(xgboost)
library(fExtremes)
library(gbm)
library(onehot)
###########################
#########_____    Fonctions utiles
###########################
# #fonction pour le calcul du taux d’erreur
# err_rate <- function(D,prediction){
#   #matrice de confusion
#   mc <- table(D$chiffre,prediction)
#   #taux d’erreur
#   #1- somme(individus classés correctement) / somme totale individus
#   err <- 1 - sum(diag(mc))/sum(mc)
#   print(paste("Error rate :",round(100*err,2),"%"))
# }
###########################
#########_____    Mise en forme, Ecrètement et tarification des sinistres graves
###########################
mePlot(severite$ClaimAmount)
.seuil.grv <- 20000
nrow(severite[which(severite$ClaimAmount>.seuil.grv),])/nrow(severite)*100
att <- data.frame(severite[which(severite$ClaimAmount<=.seuil.grv & severite$ClaimAmount>100),]
,rep(1,nrow(severite[which(severite$ClaimAmount<=.seuil.grv & severite$ClaimAmount>100),]))
)
names(att) <- c("IDpol","ClaimAmount","AttClaimNb")
att.mean <- aggregate(ClaimAmount ~ IDpol, data = att, mean)
#On renomme
names(att.mean) <- c("IDpol", "MeanClaimAmount")
base <- merge(x = frequence, y = att.mean, by = "IDpol", all.x = T)
base$MeanClaimAmount <- replace(base$MeanClaimAmount, is.na(base$MeanClaimAmount), 0)
head(base,5)
summary(base)
base <- base[-which(base$ClaimNb >0 & base$MeanClaimAmount ==0),]
#base <- base[-which(base$ClaimNb>5),]
grave <- data.frame(severite[which(severite$ClaimAmount>.seuil.grv),],rep(1,nrow(severite[which(severite$ClaimAmount>.seuil.grv),])))
names(grave) <- c("IDpol","GrvClaimAmount","GrvClaimNb")
surprime.grv <- sum(grave$GrvClaimAmount)/sum(base$Exposure)
#La surprime est de ...
surprime.grv
###########################################################
##############################_____ Modèle de cout
###########################################################
#On ne garde que les polices sinistrées
base.cout <- base[which(base$ClaimNb>0),]
################################################
###################_____    Séparation des données en 3 jeux: train, validation et test
################################################
#Les proportions que l'on veut pour nos différentes bases
proportion.train <- 0.75
porportion.valid <- 0.125
proportion.test <- 0.125
#On stocke toute les bases dans une liste de base, c'est plus simple à utiliser
#Les indices pour la base de train
sample.train <- sample.int(n = nrow(base.cout)
, size = floor(proportion.train*nrow(base.cout))
, replace = F)
#Une base temporaire qui les reste de la base initiale après la division pour la de train
base.temp <- base.cout[-sample.train,]
sample.test <- base.temp %>% nrow() %>% sample.int(n=.
, size = floor(porportion.valid/proportion.train*.)
, replace = F)
#On crée les bases et la liste
lbase.cout <- list(full = base.cout
, train = base.cout[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.cout$train,10)
head(lbase.cout$valid,10)
head(lbase.cout$test,10)
######## Flags (pour xgboost)
base.cout.oh <- predict(onehot(base.cout, stringsAsFactors = T, addNA = FALSE, max_levels = 100)
, base.cout)
base.temp <- base.cout.oh[-sample.train,]
sample.test <- base.temp[,1] %>% length() %>% sample.int(n=.
, size = floor(porportion.valid/proportion.train*.)
, replace = F)
#On crée les bases et la liste
lbase.cout.oh <- list(full = base.cout.oh
, train = base.cout.oh[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.cout.oh$train,10)
head(lbase.cout.oh$valid,10)
head(lbase.cout.oh$test,10)
# #On crée une liste des bases au format xgbMatrix
lbase.cout.xgb <- list(train = xgb.DMatrix(data = as.matrix(lbase.cout.oh$train[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$train[,'MeanClaimAmount'])
,test = xgb.DMatrix(data = as.matrix(lbase.cout.oh$test[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$test[,'MeanClaimAmount'])
,valid = xgb.DMatrix(data = as.matrix(lbase.cout.oh$valid[,-c(1,2,3,length(lbase.cout.oh$full[1,]))])
, label = lbase.cout.oh$valid[,'MeanClaimAmount'])
)
################################################
###################_____    Modélisation
################################################
#######################################
######################_____ Package GBM
#######################################
m.gbm.defaut <- gbm(data = lbase.cout$train
,formula = MeanClaimAmount ~ + VehBrand + VehAge + VehPower + DrivAge + Region + Density
,distribution = "gaussian"
,n.trees = 10000
,shrinkage = 0.01
,interaction.depth = 10
)
base.freq <- data.frame(base,data.frame(ClaimNbAnnual = base$ClaimNb/base$Exposure))
#Les proportions que l'on veut pour nos différentes bases
proportion.train <- 0.5
porportion.valid <- 0.25
proportion.test <- 0.25
#On stocke toute les bases dans une liste de base, c'est plus simple à utiliser
#Les indices pour la base de train
sample.train <- base.freq %>% nrow() %>% sample.int(n = .
, size = floor(proportion.train*.)
, replace = F)
#Une base temporaire qui les reste de la base initiale après la division pour la de train
base.temp <- base.freq[-sample.train,]
sample.test <- base.temp %>% nrow() %>% sample.int(n=.
, size = floor(porportion.valid/proportion.train*.)
, replace = F)
#On crée les bases et la liste
lbase.freq <- list(full = base.freq
, train = base.freq[sample.train,]
, test = base.temp[sample.test,]
, valid = base.temp[-sample.test,])
head(lbase.freq$train,10)
head(lbase.freq$valid,10)
head(lbase.freq$test,10)
################################################
###################_____    Modélisation
################################################
#lbase.freq$train$ClaimNb <- as.factor(lbase.freq$train$ClaimNb)
#lbase.freq$test$ClaimNb <- as.factor(lbase.freq$test$ClaimNb)
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus +offset(log(Exposure))
,distribution = "poisson"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand + VehAge  + DrivAge + Area + Region + BonusMalus +offset(Exposure)
,distribution = "poisson"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
m.gbm.defaut <- gbm(data = lbase.freq$train
,formula = ClaimNb ~  VehBrand   + DrivAge  + Region + BonusMalus +offset(Exposure)
,distribution = "poisson"
,n.trees  = 10
,shrinkage = 0.1
,interaction.depth = 7
,n.minobsinnode = 500
, train.fraction = 0.75
)
print(m.gbm.defaut)
print(head(summary(m.gbm.defaut),10))
pred <- lbase.freq$test$Exposure*predict(m.gbm.defaut, lbase.freq$test, n.trees = 10)
(pred - lbase.freq$test$ClaimNb)^2 %>% mean() %>% sqrt()
head(pred,100)
?`gbm-package`
?gbm
